{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1accc82b-65f5-4860-9fb6-4009890d34ad",
   "metadata": {},
   "source": [
    "**Attention Mechanisms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f40e9be-5952-48b1-ab84-bb5f8c151e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1939c20-d5f8-4d6a-856b-79966a7632f6",
   "metadata": {},
   "source": [
    "**We have different types of attention**\n",
    "\n",
    "(1) Simplified self attention\n",
    "(2) Self attention\n",
    "(3) Casual attention\n",
    "(4) Multi-head attention (used in GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bf790-c88d-4801-8b03-9f3924b612bc",
   "metadata": {},
   "source": [
    "**Self attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812406f8-faba-4345-af25-09c9c7e08a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     \n",
    "   [0.55, 0.87, 0.66], # journey  \n",
    "   [0.57, 0.85, 0.64], # starts   \n",
    "   [0.22, 0.58, 0.33], # with     \n",
    "   [0.77, 0.25, 0.10], # one      \n",
    "   [0.05, 0.80, 0.55]] # step  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56db91c-1122-4ef6-9b55-6c07d5cc63f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue",
          "opacity": 0.8,
          "size": 10
         },
         "mode": "markers+text",
         "text": [
          "Your",
          "journey",
          "starts",
          "with",
          "one",
          "step"
         ],
         "textposition": "top center",
         "type": "scatter3d",
         "x": [
          0.43,
          0.55,
          0.57,
          0.22,
          0.77,
          0.05
         ],
         "y": [
          0.15,
          0.87,
          0.85,
          0.58,
          0.25,
          0.8
         ],
         "z": [
          0.89,
          0.66,
          0.64,
          0.33,
          0.1,
          0.55
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 40
        },
        "scene": {
         "aspectmode": "auto",
         "aspectratio": {
          "x": 0.969546110337885,
          "y": 0.969546110337885,
          "z": 1.063807537731846
         },
         "camera": {
          "center": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "eye": {
           "x": 1.4838789105760315,
           "y": 1.4838789105760313,
           "z": 1.4838789105760315
          },
          "projection": {
           "type": "perspective"
          },
          "up": {
           "x": 0,
           "y": 0,
           "z": 1
          }
         },
         "xaxis": {
          "title": {
           "text": "X-axis"
          },
          "type": "linear"
         },
         "yaxis": {
          "title": {
           "text": "Y-axis"
          },
          "type": "linear"
         },
         "zaxis": {
          "title": {
           "text": "Z-axis"
          },
          "type": "linear"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"30bdd705-1202-4588-b2e0-6827f5b15efb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"30bdd705-1202-4588-b2e0-6827f5b15efb\")) {                    Plotly.newPlot(                        \"30bdd705-1202-4588-b2e0-6827f5b15efb\",                        [{\"marker\":{\"color\":\"blue\",\"opacity\":0.8,\"size\":10},\"mode\":\"markers+text\",\"text\":[\"Your\",\"journey\",\"starts\",\"with\",\"one\",\"step\"],\"textposition\":\"top center\",\"x\":[0.43,0.55,0.57,0.22,0.77,0.05],\"y\":[0.15,0.87,0.85,0.58,0.25,0.8],\"z\":[0.89,0.66,0.64,0.33,0.1,0.55],\"type\":\"scatter3d\"}],                        {\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":40},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"title\":{\"text\":\"Y-axis\"}},\"zaxis\":{\"title\":{\"text\":\"Z-axis\"}}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('30bdd705-1202-4588-b2e0-6827f5b15efb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3D reprsentation of the vector \n",
    "import torch\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89],  # Your   \n",
    "    [0.55, 0.87, 0.66],  # journey  \n",
    "    [0.57, 0.85, 0.64],  # starts\n",
    "    [0.22, 0.58, 0.33],  # with \n",
    "    [0.77, 0.25, 0.10],  # one\n",
    "    [0.05, 0.80, 0.55]   # step \n",
    "])\n",
    "\n",
    "# Labels for the words\n",
    "words = [\"Your\", \"journey\", \"starts\", \"with\", \"one\", \"step\"]\n",
    "\n",
    "x, y, z = inputs[:, 0], inputs[:, 1], inputs[:, 2]\n",
    "\n",
    "scatter = go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers+text', \n",
    "    marker=dict(size=10, color='blue', opacity=0.8),\n",
    "    text=words,\n",
    "    textposition=\"top center\" \n",
    ")\n",
    "\n",
    "# Create layout for the plot\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X-axis',\n",
    "        yaxis_title='Y-axis',\n",
    "        zaxis_title='Z-axis'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40) \n",
    ")\n",
    "\n",
    "# Create the figure and plot\n",
    "fig = go.Figure(data=[scatter], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e78093-04bd-40b3-9c65-0d757b37ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.8700, 0.6600])\n",
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e85449b-a208-447d-b440-7d684ce1c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_i= tensor([0.4300, 0.1500, 0.8900])\n",
      "x_i= tensor([0.5500, 0.8700, 0.6600])\n",
      "x_i= tensor([0.5700, 0.8500, 0.6400])\n",
      "x_i= tensor([0.2200, 0.5800, 0.3300])\n",
      "x_i= tensor([0.7700, 0.2500, 0.1000])\n",
      "x_i= tensor([0.0500, 0.8000, 0.5500])\n",
      "attn_scores_2= tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "#to find the attention of the second row(query), we find the dot product of the second row\n",
    "#with all other rows\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    print(f\"x_i=\", x_i)\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "\n",
    "print(f\"attn_scores_2=\", attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90639bc6-75b5-4f29-8537-e7ebc9859879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9544)\n",
      "tensor(0.9544)\n"
     ]
    }
   ],
   "source": [
    "res = 0.\n",
    "\n",
    "for idx, element in enumerate(inputs[0]):\n",
    "    res += inputs[0][idx] * query[idx]\n",
    "\n",
    "print(res)\n",
    "print(torch.dot(inputs[0], query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "453a9148-80c0-4c9e-b5b7-3d352b6d7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5617)\n"
     ]
    }
   ],
   "source": [
    "#For interpretation we normalize the attention(tensor) to know how each words are related to each other\n",
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(attn_scores_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec293ec-cb8c-4c42-9f23-cb5ca2ce3652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0afcb0c-addc-42d8-819b-7bddae818a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above normalization has limitations like if we have a big values \n",
    "#among all the list it will affect the interpretation because more attention\n",
    "#will be given to it. To solve this we use softmax basically applying exponential for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54200a48-10f2-469c-8b14-75b5b395394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "736ee29b-ec63-4c5e-aeb8-c10f4f5cd63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#the above methode can also have effects of big values so we use pytorch sofmax\n",
    "#where max.values() is remove from all values\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce7e7005-8133-4e91-acc0-110d80140e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "#comput the context vector by multiplying the attention weights by the input tensors(embedding)\n",
    "query = inputs[1] # 2nd input token is the query\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e1d7ac3-d2ee-4bb3-9da8-07acb4e434ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall: attention weight is multipying the query tensor by all input tensor.\n",
    "#recall: context weight is multiplying the attention weight with the values.\n",
    "#so it is like this compute attention scores, normalize it to get attention weight\n",
    "#then get context weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b81955-546d-4de1-b296-1ee14aae8376",
   "metadata": {},
   "source": [
    "***Computing attention weights for all input tokens***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae07d47-f806-46ca-b75e-e770c264f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "#so applying it to all input tensors to get attention scores\n",
    "attn_scores = torch.empty(6, 6)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4954c9a2-97e0-47e4-bedf-213a3c49bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "#to get all attention weight through pytorch softmax normalization\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10562485-a413-4a98-9955-bcfde0069916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "#to get all the context weight by finding dot product of attention weight and input vectors\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8a98f00-377a-4f5c-80bb-eb7564e125e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.8700, 0.6600])\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#doing something similar to gpt to get attention weight\n",
    "x_2 = inputs[1] # second input element\n",
    "print(x_2)\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "print(d_in)\n",
    "d_out = 2 # the output embedding size, d=2\n",
    "print(d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78ab2317-c997-4e4e-88df-b83e34fa08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used a random weight first but it will be optimize later for better output doing something similar to gpt\n",
    "torch.manual_seed(43)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c9d93fa-b05d-4f94-a267-b9bfb1d3a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.4540, 0.1965],\n",
      "        [0.9210, 0.3462],\n",
      "        [0.1481, 0.0858]])\n"
     ]
    }
   ],
   "source": [
    "print(W_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09d0bd7d-1fbb-4107-8e3c-8046f2be7c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.5909, 0.0659],\n",
      "        [0.7476, 0.6253],\n",
      "        [0.9392, 0.1338]])\n"
     ]
    }
   ],
   "source": [
    "print(W_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b27cb246-b18a-4a7c-95e9-1816aacb2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.5191, 0.5335],\n",
      "        [0.5375, 0.7058],\n",
      "        [0.4275, 0.2761]])\n"
     ]
    }
   ],
   "source": [
    "print(W_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8497b7bb-ad24-490a-b383-ac93b11161f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1487, 0.4659])\n"
     ]
    }
   ],
   "source": [
    "#we are only doing it for this tensor([0.5500, 0.8700, 0.6600]) to get the weight\n",
    "query_2 = x_2 @ W_query \n",
    "key_2 = x_2 @ W_key \n",
    "value_2 = x_2 @ W_value\n",
    "\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d79aa37-19a1-4e4e-9efe-8325139713ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "query.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "#getting the weights for all the input tensors\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "queries = inputs @ W_query\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "print(\"query.shape:\", queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e98a7897-5967-43f8-ab21-e8a247c6a9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2021, 0.2412],\n",
      "        [1.5953, 0.6686],\n",
      "        [1.5734, 0.6547],\n",
      "        [0.8735, 0.4213],\n",
      "        [0.7358, 0.2205],\n",
      "        [1.1442, 0.5771]])\n"
     ]
    }
   ],
   "source": [
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38e4cd83-3b75-415f-b6b4-b669dedaf98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6843, 0.5810],\n",
      "        [1.0353, 1.0898],\n",
      "        [1.0264, 1.0808],\n",
      "        [0.5671, 0.6179],\n",
      "        [0.5768, 0.6149],\n",
      "        [0.6911, 0.7432]])\n"
     ]
    }
   ],
   "source": [
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53ad3d45-a190-4119-bece-a8bee70c86dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4652, 0.2128],\n",
      "        [1.1487, 0.4659],\n",
      "        [1.1364, 0.4612],\n",
      "        [0.6829, 0.2723],\n",
      "        [0.5946, 0.2464],\n",
      "        [0.8410, 0.3340]])\n"
     ]
    }
   ],
   "source": [
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20cdb37b-5e08-4a47-aafb-676b7bce44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1440)\n"
     ]
    }
   ],
   "source": [
    "#to get the attention scores afer doing the weight of the query and keys(input tensors)\n",
    "keys_2 = keys[1] # Python starts index at 0\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90307dc8-a5a5-4444-9f29-8be34f75678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4933, 2.1440, 2.1124, 1.1998, 0.9480, 1.5832])\n"
     ]
    }
   ],
   "source": [
    "#now doing it for all input tensors\n",
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8645538b-17b4-40c4-b1ce-f1968f104051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1494, 0.2368, 0.2315, 0.1214, 0.1016, 0.1592])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#attention weight using softmax\n",
    "d_k = keys.shape[1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)\n",
    "print(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "191de36d-7d20-4481-9140-ce16c286f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8225, 0.8509])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "871e10ca-e5b9-495b-9402-cad745eda05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9772ef5-519e-4387-b042-2b38bdf8cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7878, 0.8137],\n",
      "        [0.8225, 0.8509],\n",
      "        [0.8219, 0.8502],\n",
      "        [0.7985, 0.8250],\n",
      "        [0.7941, 0.8204],\n",
      "        [0.8066, 0.8337]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(43)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d935a2f3-0b88-4e32-a73b-5e23019a3528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#we can also use linear in pytorch since it has more weight initialization than parameter\n",
    "#in pytorch\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e49a56f-d70b-4db5-8456-b7308a029132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one without weigh for keys, values and querry is the simplified self attention\n",
    "# and the one with the weight for keys, values and querry is the self attention like gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4447f35-32d3-4bfb-9067-ff35641d9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#casual attention\n",
    "#in the casual attention we don't use all input tensors for the dot products\n",
    "#we use it consecutively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5161d47d-36bd-4cf3-8182-c52dc9f10fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs) \n",
    "attn_scores = queries @ keys.T\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040274f4-35e7-4b30-bb81-0ed1658d901b",
   "metadata": {},
   "source": [
    "- The simplest way to mask out future attention weights is by creating a mask via PyTorch's tril function with elements below the main diagonal (including the diagonal itself) set to 1 and above the main diagonal set to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18bb3225-05e3-432f-a806-7bbe1f1c0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7393481c-9408-4848-b3f8-b72d489bdddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights*mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93c42327-b54d-456c-a339-eae841af2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebc80ec7-915d-4946-87a3-b7eb36fe4dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#before doing the softmax we changed all the 0.0000 to -inf to avoid error in the exponential\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71170966-cdb1-422f-8ef9-cd81272a73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#pytorch softmax where max.values() is deducted\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de40232f-a563-494b-aeff-8d32f0d7cb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#applying drop out of .5 to reduce overfitting after attention weight\n",
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) # dropout rate of 50%\n",
    "example = torch.ones(6, 6) # create a matrix of ones\n",
    "\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9f979a1-c27e-4a7d-b2a3-50c9403a1b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.1034, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3775, 0.3941, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbe57732-7587-4788-b7c4-219b7228a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting everything together for the casual attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e5b9198-08ec-4c51-8c18-1949bcef569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8eb4a4b-f643-4a88-bd38-3aef69ff735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0539, -0.1404],\n",
      "         [ 0.0628, -0.1283],\n",
      "         [ 0.0660, -0.1200],\n",
      "         [ 0.0605, -0.1099],\n",
      "         [ 0.0548, -0.0612],\n",
      "         [ 0.0548, -0.0847]],\n",
      "\n",
      "        [[ 0.0539, -0.1404],\n",
      "         [ 0.0628, -0.1283],\n",
      "         [ 0.0660, -0.1200],\n",
      "         [ 0.0605, -0.1099],\n",
      "         [ 0.0548, -0.0612],\n",
      "         [ 0.0548, -0.0847]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(43)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b95a74f-12d7-4cd6-bd80-e1453b17c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-head attention\n",
    "#this is basically running the attention mechanism many times and in parallel to get \n",
    "#different attention from the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d517cf3e-0efd-43f8-b149-0c1197bd9cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0539, -0.1404,  0.1940, -0.0992],\n",
      "         [ 0.0628, -0.1283,  0.1050,  0.1253],\n",
      "         [ 0.0660, -0.1200,  0.0757,  0.2010],\n",
      "         [ 0.0605, -0.1099,  0.0513,  0.2067],\n",
      "         [ 0.0548, -0.0612,  0.0474,  0.2251],\n",
      "         [ 0.0548, -0.0847,  0.0370,  0.2210]],\n",
      "\n",
      "        [[ 0.0539, -0.1404,  0.1940, -0.0992],\n",
      "         [ 0.0628, -0.1283,  0.1050,  0.1253],\n",
      "         [ 0.0660, -0.1200,  0.0757,  0.2010],\n",
      "         [ 0.0605, -0.1099,  0.0513,  0.2067],\n",
      "         [ 0.0548, -0.0612,  0.0474,  0.2251],\n",
      "         [ 0.0548, -0.0847,  0.0370,  0.2210]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "\n",
    "\n",
    "torch.manual_seed(43)\n",
    "\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d73e5da4-0d15-4993-ae3c-bbeb7bfc26c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98c89dea-060a-4490-ab63-f412dc78e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity lets look at what happens when executing \n",
    "#`attn_scores = queries @ keys.transpose(2, 3)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5b9be1c-9136-4eb0-ab36-46b977f199fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "source": [
    "# (b, num_heads, num_tokens, head_dim) = (1, 2, 3, 4)\n",
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "\n",
    "print(a @ a.transpose(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dca3a57b-456c-4b65-ac5d-ec56fd16d475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a1f90-c19b-4ea2-9dd9-a07cf2ea3fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4d4c6-7d53-48c0-b3f0-12c9c39af8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9b88ef1-b9fa-4412-b547-0ebf9f3e2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bbc6c3b-767b-4fd9-a85d-beb0641d4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import matplotlib\n",
    "import tiktoken\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd5bb417-ea8c-4a67-ba0a-f4971c578a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # how many total characters\n",
    "    \"context_length\": 1024, # total length of the context to be process at once\n",
    "    \"emb_dim\": 768,         # how many dimensions to encode the text like x,y,z.....\n",
    "    \"n_heads\": 12,          # total number of multi-head used\n",
    "    \"n_layers\": 12,         # total number of network layers\n",
    "    \"drop_rate\": 0.2,       # how many neurons are turned off to prevent overfitting\n",
    "    \"qkv_bias\": False       # setting bias in key, values, bias to false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d63b8884-f7fd-4e93-af1d-19e28dcc45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])  ##token embedding\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]) ##positional embedding\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"]) ##drop out of some neurons\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) ##layer normalization\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  ##adding token and positional embedding\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x) ##feed forward in neural network\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bec507fc-0625-4393-8105-3d90001689d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c2c9671a-e050-4cb0-ab24-4d7d9d1d4625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.2053, -0.3925, -0.2561,  ..., -0.1117,  1.3045,  0.3718],\n",
      "         [-0.8290,  0.4756,  1.6525,  ..., -0.3865, -0.8757,  0.9201],\n",
      "         [-0.3527,  1.1576,  0.0813,  ...,  0.7441, -1.0046,  0.9678],\n",
      "         [ 0.7347, -0.4910,  0.1743,  ..., -0.7565,  0.5852, -0.2350]],\n",
      "\n",
      "        [[ 0.0096, -0.9429,  0.1371,  ..., -0.0697,  1.6890,  0.2030],\n",
      "         [-0.0828,  1.0343,  0.0596,  ...,  0.5229,  0.1025, -0.5542],\n",
      "         [-0.1362, -0.1582,  1.8129,  ...,  1.9985, -0.4309,  0.5573],\n",
      "         [-0.4285,  0.8440, -1.5294,  ..., -1.4554,  1.6491,  1.1880]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#using gpt2 to print out the encoding dimension\n",
    "torch.manual_seed(43)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f699de4-c256-4c1b-8b89-6c362e114e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer normalization\n",
    "#this is done to scale the tensors to have a mean of 0 and std of 1\n",
    "#similar to standard scaler in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33644619-3e0c-4c70-bd47-761c9f0b1936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0610, 0.1925, 0.5409, 0.5792, 0.1095, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7171, 0.3201]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "\n",
    "# create 2 training examples with 5 dimensions (features) each\n",
    "batch_example = torch.randn(2, 5) \n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c6b3f3f-99c4-4891-a906-4187829ddb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.2472],\n",
      "        [0.1729]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0628],\n",
      "        [0.0875]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "563f577c-b428-476e-9970-99d8e0b6abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applyin the normalization which is (x-mean)/std or (x-mean)/square root of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "352a2815-e09e-4416-a9d9-fd7ab9b1cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[-0.7427, -0.2182,  1.1716,  1.3244, -0.5492, -0.9860],\n",
      "        [-0.5845, -0.5845, -0.5845, -0.5845,  1.8400,  0.4979]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[ 5.9605e-08],\n",
      "        [-1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41cabcfb-892a-4b87-ba31-7a73b7d8f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we introduce epsilon to avoid zero division error \n",
    "#normalization will now be (x-mean)/(std + epsilon)\n",
    "#or (x-mean)/(square root of variance + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c9d9158-59b9-4e6a-87ce-f2c165221930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3bca5c11-5799-41d9-827b-a5496c97ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ab3a2fec-09ba-4628-aadd-9e84b420f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[ 0.0000e+00],\n",
      "        [-4.7684e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f299f2-6137-4658-bf7d-38c1aa635802",
   "metadata": {},
   "source": [
    "- GPT use GELU activation and they use the GELU approximation for easy computation $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
    "$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "debec300-1b03-461d-bd31-cad944c2005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da4aafd0-42cf-4595-893c-1856f35ac826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing the difference between GELU(x) and RELU(x,max) \n",
    "#activation functions for nonlinearity\n",
    "#main difference is that GELU doesn't convert all negative to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c8cac28f-de20-401c-adb1-e17407fda35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "849d577a-ca67-4723-8d83-1b158d889c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d0243d6-5a75-45ff-8bf2-393f6ba34ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "#the embedding dimenion (x,y,z....) is still maintained even after feed forward\n",
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bcc530e9-5060-4ec1-bd83-0f56ba0a38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768) \n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a276722b-204e-4d6f-9cf7-02e4fb3ec9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shortcut connections\n",
    "#adding the output of previous layer to the current layer to prevent\n",
    "#vanishing gradient to attain optimization\n",
    "#like say step 0 has output 1.5, step 1 will now have ouput x+1.5 (1.5 from step 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24fc1462-dbcf-484f-b041-58097880d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a88d1ad2-cbfe-455e-af35-a1f07428e470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152039906941354\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "#example without using shortcut connections\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]  \n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3e2eef90-ce64-4d91-992f-1ebc359be781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from above we can see that the gradient isn't improving which will affect weight\n",
    "#updating and take long time to reach optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aa6b416a-54a0-43db-bc1b-c72958de9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.030894292518496513\n",
      "layers.1.0.weight has gradient mean of 0.05817604809999466\n",
      "layers.2.0.weight has gradient mean of 0.033427897840738297\n",
      "layers.3.0.weight has gradient mean of 0.021222321316599846\n",
      "layers.4.0.weight has gradient mean of 0.21083001792430878\n"
     ]
    }
   ],
   "source": [
    "#with shortcut connections to see improvement in the gradient\n",
    "torch.manual_seed(43)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a11e5bce-af0a-4335-a302-a313fe97a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ad2cd16c-29d2-42a4-8c22-0283ca3fed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163920fe-a13a-4ada-91ac-1f89be901d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4db18-df4e-4f41-84a3-0663f605cd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d668d45c-0e68-49ce-8a84-dc4abfdc302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1bb33617-768f-4c5e-b361-ef6532ed8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2d2a760d-ad50-46b8-99de-27bf0d9444f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch: tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.6503,  0.2337,  0.6657,  ..., -0.1506, -0.3917,  0.6971],\n",
      "         [-0.2998, -0.5163,  0.5684,  ..., -0.0345, -0.6387,  0.1509],\n",
      "         [-0.6652, -0.3267,  0.3492,  ...,  0.5912,  0.0244,  0.0577],\n",
      "         [-0.3140, -0.0398, -0.4212,  ...,  0.6126,  0.2533,  0.6013]],\n",
      "\n",
      "        [[-0.8339,  0.7137,  0.3360,  ...,  0.3406, -0.0520,  0.0366],\n",
      "         [-0.5656, -1.1392,  0.6023,  ..., -0.3742, -0.3061, -0.0873],\n",
      "         [ 0.2302, -0.9511,  0.4311,  ...,  0.0774,  0.7190, -0.1914],\n",
      "         [ 0.5870, -0.1081,  0.3185,  ...,  0.5165,  0.3577,  0.2377]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#using the 124M\n",
    "torch.manual_seed(43)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\", batch)\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c25f1bb5-3573-4e36-81fd-7191d23d79cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b09ad0d8-8ca1-4026-8b20-dae0a8bb550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e3651bbe-32f3-4f22-9a77-44b8b7350f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "68671203-03a7-441b-8c42-6f76ab01ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# Convert to megabytes\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041f060-1012-49e1-8dbe-af1a88b04ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bc1d0-972c-44a3-bdce-ecf2c398050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "49eca14d-75ce-4adf-86ad-a26f93470b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "12e5cdfe-501f-47f1-80db-8aa347c0cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#greedy decoding: putting more attentionn to the words having higher probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0b1b496f-2b7b-49ea-9880-6bb564254fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24d37247-71b7-4da8-8d43-a2b8e40a4994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [8241, 318, 2641, 30]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "start_context = \"Who is inside?\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "45b7029f-424b-4aac-a8ed-e7a88ab8a529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[ 8241,   318,  2641,    30, 27359, 36201, 38339, 19468, 10709, 14512]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disable dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff081bec-b585-41a4-8eab-848607b44f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is inside?aber hrs471 grancommun !=\n"
     ]
    }
   ],
   "source": [
    "#decoding it back. Random oup[ut now because the model isn't trained yet.\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee850133-2c30-4673-ac13-dfe1ed28dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ce668-c3e8-47a2-99d1-c05425da282d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c1ea3e35-9288-4700-bf78-ae1e23fbde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model for better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "19716998-6cd7-4f44-b72d-1182ed007445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.4.1\n",
      "tensorflow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "78df30b2-034e-483f-bc53-8578d07400c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, \n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,  \n",
    "    \"n_layers\": 12,  \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False \n",
    "}\n",
    "\n",
    "torch.manual_seed(43)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "07cc9b44-e442-45fb-ab99-80e7b832a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you snag neurotHearterv Thr Toledo 560 Peyton CLA visibly\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "28132ba9-20ca-4036-9dde-46e7f28cc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still random output in the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ede97f9f-8834-40d6-b230-0ee205b02e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f3b83187-5236-41cd-ab3d-ccd329cbec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b4cd3a0-0939-4b61-80fa-1a2cd4ea26f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[23311],\n",
      "         [37040],\n",
      "         [ 3520]],\n",
      "\n",
      "        [[13117],\n",
      "         [ 7982],\n",
      "         [39126]]])\n"
     ]
    }
   ],
   "source": [
    "#taking the maximum token based on probability\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bb4eaa6a-6ac9-4c93-b02e-bb7e22538548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  predatorsvir remain\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8c80f645-8592-4046-938b-34bab521b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([1.9425e-05, 1.4349e-05, 3.6366e-05])\n",
      "Text 2: tensor([3.0539e-05, 1.1002e-05, 1.4961e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9d8d72df-5996-4107-9e80-485a658ec4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.8490, -11.1518, -10.2219, -10.3965, -11.4175, -11.1100])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7a526f71-8753-4349-a15c-1cc56d425f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8578)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5ff66600-528e-4584-9644-401a219dc514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8578)\n"
     ]
    }
   ],
   "source": [
    "#change to positive value\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0cbd2ceb-7a4a-4943-b4bf-56e574a6f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7e6660d0-a3d8-4b38-8564-aa104f5624dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "39f4a7dc-cdd0-4082-9568-054beeaac18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the loss using cross entropy which is -log(probabilty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ff632905-1015-45f5-b5b0-83eb2fac1dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8578)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4cd95a45-ffad-43c5-8b91-af949b8ab541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(51936.6758)\n"
     ]
    }
   ],
   "source": [
    "#sometimes perpleixty is used whihch is exponential(cross entropy)\n",
    "#it tells how many tokens the output is obtained from\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)\n",
    "#it means that the output is obtained from 51936.6758 tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1d0a1a87-68bb-4a85-abdf-0fa47cfbcc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"Harry_porter.txt\"\n",
    "url = \"https://github.com/Olanrewajuemmanuelabiodun/Building_LLM/blob/main/Harry_porter.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ccded7c6-c2a7-47d8-8789-cce8fab667da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
      "starts, there was nothing abo\n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "97767cad-4e28-4b96-a741-2ab89a1e14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itting astride it. He\n",
      "was almost twice as tall as a normal man and at least five times as wide. He\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1dbef14b-4c0f-4d60-bf13-8599969d4490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20042\n",
      "Tokens: 5668\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6649ba08-603a-489c-8c33-4ba5f8acedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0e3448b6-f596-4d63-838e-45ceb30f6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "df14f282-ee36-4952-a648-691337ec6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset splitting\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.80\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(43)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ded232fe-fb95-4492-a5e2-a712193103dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking purpose\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9a1e1b6e-ab3f-4057-9251-7dce6379ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3dd2d437-1cb5-46ee-9d3c-7937113091af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4096\n",
      "Validation tokens: 1024\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0e18446b-af15-4d77-a577-25c53ad37688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "495fb8fc-a976-4b89-8723-cbc02fba8f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.998939156532288\n",
      "Validation loss: 10.99402666091919\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) \n",
    "torch.manual_seed(43) \n",
    "\n",
    "with torch.no_grad():  # Removed the typo 'yet'\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e3cde919-630c-4e96-97f5-b8fbe20cf23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients (do the backpropagation)\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4af1b482-f30b-4ab6-97dc-c33209e209d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.436, Val loss 10.482\n",
      "Ep 1 (Step 000005): Train loss 8.893, Val loss 8.769\n",
      "Every effort moves you                              .   .             \n",
      "Ep 2 (Step 000010): Train loss 8.312, Val loss 8.308\n",
      "Ep 2 (Step 000015): Train loss 7.749, Val loss 7.734\n",
      "Every effort moves you.  .    .  .     \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b71445ab-235e-4f83-a03b-23c923c3fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) \n",
    "\n",
    "    ax2 = ax1.twiny()  \n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) \n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f68af31f-f401-44c2-924e-5694e2b11105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you.\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ceb5bec0-ed55-4026-915a-74456f6187d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7663943d-145b-4e74-9caf-436b879f8816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d6602c7c-1c9a-43da-895d-0e2609564993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the effect of setting temperature\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [14, 0.2, 6]  \n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "455bc532-e5fe-4157-ac38-427f169bf6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seeing how tempearure affects the next word interms of probabilty of choosen the\n",
    "#next word\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "802f8e6f-d3f5-42c0-9496-3d5f4e163622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "914 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "86 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2cbd24b9-b410-4f68-a89b-0aaae717d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 x closer\n",
      "84 x every\n",
      "51 x effort\n",
      "223 x forward\n",
      "75 x inches\n",
      "56 x moves\n",
      "39 x pizza\n",
      "206 x toward\n",
      "107 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bbb9dd22-0689-4910-839b-ccbe7ffabcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using probability can put too much dependence on a particular word so \n",
    "#we adopt k_sampling by turning off some words that has lower probabilty\n",
    "#before using temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8b5fc2a1-4768-4e57-9a17-31b57646dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100, 1.7900])\n",
      "Top positions: tensor([3, 7, 0, 8])\n"
     ]
    }
   ],
   "source": [
    "#considering only top three probabilty and the rest are turned to -inf \n",
    "#so when taking the softmax they will not get zero division error\n",
    "top_k = 4\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b6fc68ae-85a1-4454-8d4e-4c6d89cf1f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800, 1.7900])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e30be637-e904-40cd-9ae6-8468fb2eb0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0612, 0.0000, 0.0000, 0.5752, 0.0000, 0.0000, 0.0000, 0.3595, 0.0040])\n"
     ]
    }
   ],
   "source": [
    "#and the probability is summing to one\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "86d49bc1-dd16-4dda-b2bd-a6f704fb3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.2, top_k=4, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f3ad0fdf-3ef0-4317-86f4-70e41b1cc38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you wasand\n",
      "\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "408dac96-d496-49f0-8544-f6f9650cf1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "69fa7f0d-05af-4f52-a96e-6eca88e1506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3cd34afc-51bf-479d-9946-5ec2ff646268",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3216454f-5375-40d7-bc7d-934bdbe1c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2d2d8695-8a24-448d-9624-a9dd025a9a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "tqdm version: 4.66.2\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "57aee2c8-f861-4636-b98d-55480d649566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative import from the gpt_download.py contained in this folder\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0ecdaf8d-133f-4114-ac56-2c1e0fd713fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 57.8kiB/s]\n",
      "encoder.json: 100%|| 1.04M/1.04M [00:00<00:00, 1.49MiB/s]\n",
      "hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 26.9kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|| 498M/498M [19:37<00:00, 423kiB/s]\n",
      "model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 1.33MiB/s]\n",
      "model.ckpt.meta: 100%|| 471k/471k [00:00<00:00, 611kiB/s]\n",
      "vocab.bpe: 100%|| 456k/456k [00:00<00:00, 467kiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f9a1a94d-d118-4fd5-854e-ab81ee33e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "aa57e6cc-34da-4d60-bf55-a2e0c3131d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3f33c176-fbdc-46cb-9936-bcec675565b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "97c781a4-3549-48eb-b1be-66141bb322fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ceb9c89c-c0e9-4600-96fc-a89dfdac6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "30d1f124-9bd8-475b-a0cf-06dec3afa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c2efc7e7-3024-4d33-900b-b4a25b3007c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you along your life, but it is no substitute for love. For love and purpose, it can be life or death,\" she\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2cd97-60d8-46e9-aadc-33ed79c67429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now in the above result the output is performing better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
