# Building a Large Language Model (LLM)

This notebook demonstrates the process of building a **Large Language Model (LLM)** from scratch. The key components of this project include:

## Data Processing
- **Token Embedding**  
- **Positional Embedding**  

## Attention Mechanism
- **Attention Scores**  
- **Attention Weights**  
- **Context Weights**  
- **Query, Key, and Value**  
- **Simplified Self-Attention**  
- **Full Self-Attention**  
- **Causal Attention**  
- **Multi-Head Attention**  

## Model Training
- **Training the LLM**  
- **Evaluating the Model**  

This notebook provides a comprehensive guide to the foundational concepts and practical implementation of the key components of LLMs.

## Additional Files
You can access other related files [here](https://drive.google.com/drive/folders/1-Dz0yjATOFrucYfXnrgB6fo-rM1xPLXW?usp=drive_link).
