# Building_LLM

This notebook demonstrates the process of building a **Large Language Model (LLM)** from scratch. The key components include:

## Data Processing
- Token Embedding  
- Positional Embedding  

## Attention Mechanism
- Attention Scores  
- Attention Weights  
- Context Weights  
- Query, Key, and Value  
- Simplified Self-Attention  
- Full Self-Attention  
- Causal Attention  
- Multi-Head Attention  

## Model Training
- Training the LLM  
- Evaluating the Model  

This notebook provides a comprehensive guide to the foundational concepts and practical implementation of LLM components.
