{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf40dd3-e1ac-4021-b691-be9ce13c398e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Print the first 200 characters. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a24e8aec-1e9e-4853-aed6-350904cf8184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 20042\n",
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
      "starts, there was nothing about the cloudy sky outside to suggest that strange\n",
      "and mysterious things would soon be happening all o\n"
     ]
    }
   ],
   "source": [
    "# Open the file and read its contents\n",
    "with open(\"Harry_porter.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# Print the total number of characters\n",
    "print(\"Total number of characters:\", len(raw_text))\n",
    "\n",
    "# Print the first 200 characters\n",
    "print(raw_text[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a3482-c409-4289-be77-875605d3381d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Uisng re.split for the character splitting. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3ce9d860-cf67-4fdf-8051-358a41b9bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'everyone.', ' ', 'We,', ' ', 'are', ' ', 'still', ' ', 'testing.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, everyone. We, are still testing.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc35870-ffa2-4bb9-8f66-fe907ea25d0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Modify the splitting so sepcial characters can be split too </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c4ccbd4b-b5dc-4fcf-88c5-da2ec82b525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'everyone', '.', '', ' ', 'We', ',', '', ' ', 'are', ' ', 'still', ' ', 'testing', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217ee9a-8529-4008-849a-1006c443320c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Removing reductant white space characters iin the splitting </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5f8ce436-21b2-4395-b193-31a34eb1342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'everyone', '.', 'We', ',', 'are', 'still', 'testing', '.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed7219-7829-4218-9534-2ebcdaf5a059",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Tokenization with special characters and removing white spaces for better tokenization</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8616cef8-5858-4837-8624-ee4400945e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd6245-caa1-4abd-9b33-55fe899d6cc1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Applying the tokenization to the harry portext book</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aca0ad11-cd8c-4939-9a3a-01009cecbd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'Mr', '.', 'and', 'Mrs', '.', 'Dursley', 'woke', 'up', 'on', 'the', 'dull', ',', 'gray', 'Tuesday', 'our', 'story', 'starts', ',', 'there', 'was', 'nothing', 'about', 'the', 'cloudy', 'sky', 'outside', 'to', 'suggest', 'that', 'strange', 'and', 'mysterious', 'things', 'would', 'soon', 'be', 'happening', 'all', 'over', 'the', 'country', '.', 'Mr', '.', 'Dursley', 'hummed', 'as', 'he', 'picked', 'out', 'his', 'most', 'boring', 'tie', 'for', 'work', ',', 'and', 'Mrs', '.', 'Dursley', 'gossiped', 'away', 'happily', 'as', 'she', 'wrestled', 'a', 'screaming', 'Dudley', 'into', 'his', 'high', 'chair', '.', 'None', 'of', 'them', 'noticed', 'a', 'large', ',', 'tawny', 'owl', 'flutter', 'past', 'the', 'window', '.', 'At', 'half', 'past', 'eight', ',', 'Mr', '.', 'Dursley', 'picked', 'up']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8bf47aff-b52c-4de3-87f0-1df919501e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4307\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb9ae4d2-5182-4a8c-883b-f3cd8dc61b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2e194-4875-4529-aa01-7c3fcc1f7b19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Vocabulary token: Involves ranking the text alphabetically and sorted with number attached to them</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e5a78fed-41db-4b8e-9e34-6e3dc69c4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('(', 1)\n",
      "(')', 2)\n",
      "(',', 3)\n",
      "('.', 4)\n",
      "(':', 5)\n",
      "(';', 6)\n",
      "('?', 7)\n",
      "('A', 8)\n",
      "('About', 9)\n",
      "('After', 10)\n",
      "('Albus', 11)\n",
      "('All', 12)\n",
      "('Although', 13)\n",
      "('And', 14)\n",
      "('As', 15)\n",
      "('At', 16)\n",
      "('Bonfire', 17)\n",
      "('Britain', 18)\n",
      "('But', 19)\n",
      "('Can’t', 20)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81483c81-f860-405a-9707-9b9c6e36490e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "--Encode and Decode    \n",
    "\n",
    "Step 1: Store the vocabulary as a class attribute for access in the encode and decode methods\n",
    "    \n",
    "Step 2: Create an inverse vocabulary that maps token IDs back to the original text tokens\n",
    "\n",
    "Step 3: Process input text into token IDs\n",
    "\n",
    "Step 4: Convert token IDs back into text\n",
    "\n",
    "Step 5: Replace spaces before the specified punctuation\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b93796b-70dd-4577-b04a-b1347448f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764f264-696f-4573-859e-3adae67dcab7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Trying out an example of the deocde and decode</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b48f6f5c-a4a9-4289-b66d-e8f34e0769a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119, 1028, 745, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"What you say?\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "666aaf09-a23e-457c-a207-2b2577c5392a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What you say?'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6f2ba-95b4-4937-b86b-3a1d3e09808d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "If any character is in the example and not in the trianing it will show error</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "851b10b6-2963-4828-9576-f34d3955dd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Messi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Messi is not in the Harry_porter text\u001b[39;00m\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessi do you like tea?\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[121], line 12\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      7\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.:;?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m      9\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Messi'"
     ]
    }
   ],
   "source": [
    "#Messi is not in the Harry_porter text\n",
    "text = \"Messi do you like tea?\" \n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33805a-5684-4829-aca0-4e8378349b10",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In the previous example Messi is not in the training text. So to solve that we\n",
    "are going to use another decode method. To solve that we can use a new token to accomodate\n",
    "for unknown text which is <|unk|> and also to seperate between two different text we\n",
    "are going to use <|endoftext|>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a8a44319-9402-48c2-af2e-5c973af04fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "\n",
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "defd8610-d2d5-4ebe-9e66-6cff9f4c0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('“You', 1085)\n",
      "('“You’d', 1086)\n",
      "('“but', 1087)\n",
      "('“everyone”', 1088)\n",
      "('“is', 1089)\n",
      "('“—', 1090)\n",
      "('”', 1091)\n",
      "('”A', 1092)\n",
      "('<|endoftext|>', 1093)\n",
      "('<|unk|>', 1094)\n"
     ]
    }
   ],
   "source": [
    "#To see the changes of the two new encoding\n",
    "for i, item in enumerate(list(vocab.items())[-10:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4b605c70-45fc-4e11-94dd-7b16ddbfe795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6608b27-d56f-4688-be6a-e9b8de1c5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi do you like tea? <|endoftext|> You sure it is raining.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Messi do you like tea?\"\n",
    "text2 = \"You sure it is raining.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "20d29b9f-1834-40f7-a10f-1a1982cc1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1094, 316, 1028, 545, 881, 7, 1093, 124, 862, 504, 502, 1094, 4]\n"
     ]
    }
   ],
   "source": [
    "decode = tokenizer.encode(text)\n",
    "print(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "19090d4f-beee-4eda-bfab-3c3f044196cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|> do you like tea? <|endoftext|> You sure it is <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "encode = tokenizer.decode(decode)\n",
    "print(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960305c8-8f87-4001-ac49-a1d755abc8cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "We also have some other options like:\n",
    "[BOS] (beginning of sequence)\n",
    "[EOS] (end of sequence):\n",
    "[PAD] (padding): When training LLMs with batch sizes larger than one,\n",
    "the batch might contain texts of varying lengths.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81115576-edf2-4848-bf46-30759b96b9d3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "GPT models doesn't use an <|unk|> token but used byte pair encoding tokenizer, which breaks\n",
    "down words into subword units and more easier to decode and decode and get semantic \n",
    "meaning of the text\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cd166-9d13-4c48-91f6-a9d0d538ac7b",
   "metadata": {},
   "source": [
    "**Byte Pair Encoding Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "be6e875c-8e5c-46f5-a239-0b10cc4aea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tiktoken from openai\n",
    "import importlib\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "16208858-6a93-4fb8-b70e-088664b29cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "757924dd-d2a0-48b3-a864-9784bc1bfd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36479, 72, 466, 345, 588, 8887, 30, 13, 1639, 1654, 340, 318, 43079, 13, 2061, 345, 910, 30]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Messi do you like tea?.\" \"You sure it is raining.\"\n",
    "     \"What you say?\"\n",
    ")\n",
    "\n",
    "encode = tokenizer.encode(text)\n",
    "\n",
    "print(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8aba9105-b6cc-4b61-a379-e0c014ad6dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi do you like tea?.You sure it is raining.What you say?\n"
     ]
    }
   ],
   "source": [
    "decode = tokenizer.decode(integers)\n",
    "\n",
    "print(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "886148f5-0fda-4d11-8880-d336cc1e882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5668\n"
     ]
    }
   ],
   "source": [
    "#encoding the harry_porter text\n",
    "with open(\"Harry_porter.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "encode = tokenizer.encode(raw_text)\n",
    "print(len(encode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766f1f0-6f88-47e3-a952-2f9752881559",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Slidding window in LLM. Shifting the output by 1. Like input is\n",
    "    a, b, c, d abd output is b, c, d, e\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5c21e301-41ea-49bf-9a17-a05039e822c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [2215, 1770, 13, 290]\n",
      "y:      [1770, 13, 290, 9074]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = encode[:context_size]\n",
    "y = encode[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f401a119-42bf-4f9e-a436-21d9ffe76e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2215] ----> 1770\n",
      "[2215, 1770] ----> 13\n",
      "[2215, 1770, 13] ----> 290\n",
      "[2215, 1770, 13, 290] ----> 9074\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = encode[:i]\n",
    "    desired = encode[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec82dca0-93ac-4327-ae3c-b10b20644cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When ---->  Mr\n",
      "When Mr ----> .\n",
      "When Mr. ---->  and\n",
      "When Mr. and ---->  Mrs\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = encode[:i]\n",
    "    desired = encode[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59312d8e-6079-4e05-9f76-3cfb0cd9b0a2",
   "metadata": {},
   "source": [
    "**IMPLEMENTING A DATA LOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "39a0bbe5-1995-4c37-83ef-d01210a99f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c64ce5cd-b730-49c3-85f4-01cda1bb5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c2cde6d-e140-4901-9807-e9aedda23864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff9930-71af-4017-b381-4a42a3e06c34",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "#recall on how context, stride and sliding window works.\n",
    "\n",
    "Context: How many elements are included in the window at one time (length of the input).\n",
    "\n",
    "Stride: The size of the jump when sliding the window forward (controls overlap).\n",
    "\n",
    "Sliding Window: The process of moving the window across the sequence to extract data step-by-step. \n",
    "\n",
    "Say words is a,b,c,d, e, f, g, h,i.\n",
    "\n",
    "Lets say context = 3, sliding window is 1, stride is 2\n",
    "\n",
    "0:\n",
    "Input: a, b, c. ouput: b,c,d\n",
    "\n",
    "1:\n",
    "Input: c,d,e outpu: d,e,f\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6048197d-29f2-478f-8417-f6a466afcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Harry_porter.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "da70144a-05c8-4139-ad74-409d6d3cc79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1\n",
      "[tensor([[2215, 1770,   13,  290]]), tensor([[1770,   13,  290, 9074]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=2, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "43b97480-ae45-4167-a22e-db92c4f75fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  13,  290, 9074,   13]]), tensor([[ 290, 9074,   13,  360]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d2905fc1-14e3-4884-ac57-5607c50cc459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[9074,   13,  360, 1834]]), tensor([[  13,  360, 1834, 1636]])]\n"
     ]
    }
   ],
   "source": [
    "third_batch = next(data_iter)\n",
    "print(third_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8b3e9c4e-1d53-4727-9d4e-0174b46e834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[ 2215,  1770,    13,   290],\n",
      "        [ 9074,    13,   360,  1834],\n",
      "        [ 1636, 19092,   510,   319],\n",
      "        [  262, 19222,    11, 12768],\n",
      "        [ 3431,   674,  1621,   198],\n",
      "        [  301,  5889,    11,   612],\n",
      "        [  373,  2147,   546,   262],\n",
      "        [40026,  6766,  2354,   284]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 1770,    13,   290,  9074],\n",
      "        [   13,   360,  1834,  1636],\n",
      "        [19092,   510,   319,   262],\n",
      "        [19222,    11, 12768,  3431],\n",
      "        [  674,  1621,   198,   301],\n",
      "        [ 5889,    11,   612,   373],\n",
      "        [ 2147,   546,   262, 40026],\n",
      "        [ 6766,  2354,   284,  1950]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386731a-399e-4016-840e-b361db5c64ea",
   "metadata": {},
   "source": [
    "**CREATE TOKEN EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f27946a-40c9-4aa1-abdc-226123ffa255",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "54cf14cd-0f11-4a3f-aaed-ce50f515ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim,max_norm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5ca1019c-4bf9-4b1e-b51c-336b7b2147c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.9269,  1.4873, -0.4974],\n",
      "        [ 0.4396, -0.7581,  1.0783],\n",
      "        [ 0.8008,  1.6806,  0.3559],\n",
      "        [-0.6866,  0.6105,  1.3347],\n",
      "        [-0.2316,  0.0418, -0.2516],\n",
      "        [ 0.8599, -0.3097, -0.3957]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f328deb6-e370-4ce5-981a-ba2b0deacea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7756,  0.5986, -0.2002]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "56a8e5f8-9d74-4056-9557-e0e4914aa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4225,  0.8867,  0.1878],\n",
      "        [-0.4237,  0.3767,  0.8237],\n",
      "        [ 0.8599, -0.3097, -0.3957],\n",
      "        [ 0.3164, -0.5456,  0.7760]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218b0d7-715c-49b9-bdea-100e1e9bb710",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Positional encoding.\n",
    "Apart from encoding we also need to do positional encoding to get proper meaning of the\n",
    "sentence. The positional encoding can be absolute encoding (considering only particular word) or relative encoding (considering the word relative to other words) as used in chatgpt\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8659ef77-e7be-425a-a875-eb8870d63177",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0269c5b7-2311-4ad6-a772-a11437df02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4,\n",
    "    stride=4, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "691d8a17-4655-4f72-9b16-dd284f8f1aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[ 2215,  1770,    13,   290],\n",
      "        [ 9074,    13,   360,  1834],\n",
      "        [ 1636, 19092,   510,   319],\n",
      "        [  262, 19222,    11, 12768],\n",
      "        [ 3431,   674,  1621,   198],\n",
      "        [  301,  5889,    11,   612],\n",
      "        [  373,  2147,   546,   262],\n",
      "        [40026,  6766,  2354,   284]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aa290415-985c-4213-90ac-9fd7b02102da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "79bc6409-f57b-49a1-bfec-230dc57642a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4a1ee579-a219-4c6f-a8ec-0a6e40c563e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "03169ba6-12fd-44d7-9701-b519875803d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99618af-79c9-4363-97fa-c52819bde05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1ff6b-b6da-400a-8735-af10900a5958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
